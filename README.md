---
title: Hallucination Hunter
emoji: âš¡
colorFrom: red
colorTo: yellow
sdk: streamlit
sdk_version: 1.37.0
app_file: app.py
pinned: true
license: apache-2.0
tags:
  - evalops
  - llm-evaluation  
  - groundedness
  - mlops
---

# Hallucination Hunter âš¡

**Automated Groundedness & Relevance Testing for Industrial Agents**

## ğŸ¯ Purpose

Evaluate LLM responses for:
- **Groundedness** - Is the response grounded in source documents?
- **Relevance** - Does it answer the actual question?
- **Coherence** - Is the reasoning logical?
- **Completeness** - Are all aspects addressed?

## ğŸš€ Features

- Upload test cases (CSV format)
- Compare multiple models (GPT-4, Gemini, Claude)
- Visualize evaluation metrics
- Export detailed reports

## ğŸ“Š Metrics Dashboard

| Metric | GPT-4 | Gemini Pro | Claude |
|--------|-------|-----------|--------|
| Groundedness | 92% | 89% | 95% |
| Relevance | 88% | 91% | 87% |
| Coherence | 94% | 90% | 93% |

## ğŸ‘¤ Author

**David Fernandez** | Industrial AI Engineer
- ğŸŒ [Portfolio](https://www.davidfernandez.dev)
